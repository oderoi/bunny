"""
Removed: Python fallback inference engine using llama-cpp-python.
This project now requires the native llama.cpp `llama-server` exclusively for inference.
"""
